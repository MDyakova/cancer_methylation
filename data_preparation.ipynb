{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33565323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# from pyspark_dist_explore import hist\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import array\n",
    "from pyspark.sql.types import FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab123b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIRECTORY = \"data\"\n",
    "DATA_FILE_NAME = \"cancer_methylation_v1.txt\"\n",
    "DATA_FILE_NAME_NEW = \"leukemia_met3\"\n",
    "\n",
    "N_STRINGS_INFO = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ffd35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create spark session\n",
    "spark = (\n",
    "    SparkSession.builder.master(\"local\")\n",
    "    .appName(\"Colab\")\n",
    "    .config(\"spark.driver.memory\", \"32g\")\n",
    "    .config(\"spark.executor.cores\", \"1\")\n",
    "    .config(\"spark.cores.max\", \"1\")\n",
    "    .config(\"spark.memory.offHeap.enabled\", \"true\")\n",
    "    .config(\"spark.memory.offHeap.size\", \"100g\")\n",
    "    .config(\"spark.sparkContext.setLogLevel\", \"ERROR\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811aea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create spark dataframe\n",
    "df = spark.read.csv(\n",
    "    os.path.join(WORK_DIRECTORY, DATA_FILE_NAME),\n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    "    sep=\"\\t\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63da69ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetInfo:\n",
    "    \"\"\"\n",
    "    The class gets information from the entire dataset.\n",
    "\n",
    "    Methods:\n",
    "    1. information_strings: get the first few strings with information\n",
    "                            about cancer type and tissue.\n",
    "    2. cancer_types: show the count of samples for each cancer type.\n",
    "    3. cancer_tissue_types: show the count of samples for each cancer and tissue type.\n",
    "    4. filter_type: filter rows with the nessesary type of cancer.\n",
    "    5. column_names: return dataset columns for the necessary type of cancer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def information_strings(self, n_strings=3):\n",
    "        self.information = self.data.limit(n_strings)\n",
    "        self.information = self.information.to_pandas_on_spark()\n",
    "        self.information = self.information.set_index(\"sample_id\")\n",
    "        self.information = self.information.transpose()\n",
    "        self.information = self.information.reset_index()\n",
    "        self.information = self.information.rename(columns={\"index\": \"sample\"})\n",
    "\n",
    "    def cancer_types(self, n_strings=10):\n",
    "        print(\n",
    "            self.information.groupby(by=[\"cancer\"], as_index=False)\n",
    "            .count()\n",
    "            .sort_values(by=[\"cancer\"])\n",
    "            .head(n_strings)\n",
    "        )\n",
    "\n",
    "    def cancer_tissue_types(self, n_strings=10):\n",
    "        print(\n",
    "            self.information.groupby(by=[\"cancer\", \"tissue\"], as_index=False)\n",
    "            .count()\n",
    "            .sort_values(by=[\"cancer\", \"tissue\"])\n",
    "            .head(n_strings)\n",
    "        )\n",
    "\n",
    "    def column_names(self):\n",
    "        columns = self.information[\"sample\"].unique().to_list()\n",
    "        return columns\n",
    "\n",
    "    def filter_type(self, cancer_filter):\n",
    "        self.information = self.information[\n",
    "            (self.information[\"cancer\"] == cancer_filter)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a643402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a dataset with information about cancer and tissue types\n",
    "info = GetInfo(df)\n",
    "info.information_strings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe322a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table with counts of each cancer type\n",
    "info.cancer_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53594019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the necessary cancer type for analysis\n",
    "info.filter_type(\"acute myeloid leukemia\")\n",
    "columns_list = info.column_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1267a2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table with counts of each tissue type in the filtered dataset\n",
    "info.cancer_tissue_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd040b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreparing:\n",
    "\n",
    "    \"\"\"\n",
    "    The class prepares the dataset for analysis.\n",
    "\n",
    "    Methods:\n",
    "    info_remove: remove the first rows with sample information.\n",
    "    get_samples: get rows with necessary samples for cancer type.\n",
    "    col_rename: rename columns without '-'\n",
    "                (necessary for spark functions).\n",
    "    na_string_replace: change the 'NA' string to None.\n",
    "    na_strings_remove: remove strings with a count missing value\n",
    "                more than max_na_count.\n",
    "    data_to_float: change data types to float.\n",
    "    quartile_range: remove strings ranging between 25% quantile and\n",
    "                75% quantile less than delta.\n",
    "    save_dataset: save dataset to CSV\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, columns):\n",
    "        self.data = data\n",
    "        self.columns = columns\n",
    "\n",
    "    def info_remove(self, n_strings=3):\n",
    "        self.data = self.data.withColumn(\"index\", monotonically_increasing_id())\n",
    "        self.data = self.data.filter((self.data[\"index\"] >= n_strings))\n",
    "\n",
    "    def col_rename(self):\n",
    "        self.columns = [col.replace(\"-\", \"\") for col in self.columns]\n",
    "        self.data = self.data.toDF(*self.columns)\n",
    "\n",
    "    def get_samples(self):\n",
    "        self.columns.insert(0, \"sample_id\")\n",
    "        self.data = self.data.select(self.columns)\n",
    "\n",
    "    def na_string_replace(self):\n",
    "        self.data = self.data.na.replace(\"NA\", None)\n",
    "\n",
    "    def na_strings_remove(self, max_na_count=50):\n",
    "        self.data = self.data.withColumn(\n",
    "            \"numNulls\", sum(self.data[col].isNull().cast(\"int\") for col in self.columns)\n",
    "        )\n",
    "        self.data = self.data.filter((self.data[\"numNulls\"] <= max_na_count))\n",
    "\n",
    "    def data_to_float(self):\n",
    "        self.data = self.data.select(\n",
    "            *(\n",
    "                col(c).cast(\"float\").alias(c) if c != \"sample_id\" else col(c).alias(c)\n",
    "                for c in self.columns\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def quartile_range(self, delta=0.1):\n",
    "        self.data = self.data.fillna(0, subset=None)\n",
    "\n",
    "        combined = array(*(col(x) for x in self.columns[1:]))\n",
    "        median_udf = udf(\n",
    "            lambda xs: float(np.percentile(xs, 75) - np.percentile(xs, 25)), FloatType()\n",
    "        )\n",
    "        self.data = self.data.withColumn(\"mean\", median_udf(combined))\n",
    "\n",
    "        self.data = self.data.filter((self.data[\"mean\"] > delta))\n",
    "\n",
    "    def save_dataset(self, directory):\n",
    "        self.data.repartition(1).write.option(\"header\", True).csv(directory, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83960810",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep = DataPreparing(df, columns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbe8167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get subset with necessary cancer type\n",
    "data_prep.info_remove()\n",
    "data_prep.get_samples()\n",
    "data_prep.col_rename()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2f11d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unconfident rows\n",
    "data_prep.na_string_replace()\n",
    "data_prep.na_strings_remove()\n",
    "data_prep.data_to_float()\n",
    "data_prep.quartile_range()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867010cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataset to CSV\n",
    "data_prep.save_dataset(os.path.join(WORK_DIRECTORY, DATA_FILE_NAME_NEW))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dc1236",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
